{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of Object Detection Models based on Detectron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Development Environment\n",
    "1. Environments\n",
    "    * GPU: RTX3070 8GB\n",
    "    * OS: Ubuntu20.04\n",
    "    * CUDA: 11.3\n",
    "    * Pytorch==1.10\n",
    "    * Detectron2==0.6\n",
    "\n",
    "2. Installation\n",
    "    ```bash\n",
    "    sudo apt-get install -y python3-dev python3-venv\n",
    "    python3 -m venv env\n",
    "    source env/bin/activate\n",
    "    python -m pip install pip -U\n",
    "    python -m pip install -r requirements.txt\n",
    "    python -m ipykernel install --user --name env --display-name ensemble_detectron2\n",
    "    python -m pip install \"git+https://github.com/facebookresearch/detectron2@v0.6\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c http://images.cocodataset.org/zips/val2017.zip\n",
    "!unzip val2017.zip\n",
    "!rm val2017.zip\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip\n",
    "!rm annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "from detectron2.data.build import build_detection_test_loader\n",
    "from detectron2.evaluation.evaluator import inference_on_dataset\n",
    "from detectron2.evaluation.evaluator import inference_context\n",
    "from detectron2.structures import Instances, Boxes\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "import ensemble_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Models, Data and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"dataset_val\", {}, \"./annotations/instances_val2017.json\", \"./val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "Loading config /home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_configs = [\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    # \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    # \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    # \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    # \"faster_rcnn_R_101_C4_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    # \"retinanet_R_101_FPN_3x.yaml\",\n",
    "]\n",
    "\n",
    "models = dict()\n",
    "for config in model_configs:\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{config}\"))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{config}\")\n",
    "    cfg.DATASETS.VAL = (\"dataset_val\",)\n",
    "\n",
    "    models[config] = DefaultPredictor(cfg).model\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.DATASETS.VAL = (\"dataset_val\",)\n",
    "val_loader = build_detection_test_loader(cfg, \"dataset_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:25<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "faster_rcnn_R_101_C4_3x.yaml\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.614\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for config, model in models.items():\n",
    "    evaluator = COCOEvaluator(\"dataset_val\", False, output_dir=f\"results/{config.split('.')[0]}\")\n",
    "    evaluator.reset()\n",
    "    with inference_context(model), torch.no_grad():\n",
    "        iter = tqdm(val_loader, total=len(val_loader))\n",
    "        for idx, inputs in enumerate(iter):\n",
    "            outputs = model(inputs)\n",
    "            torch.cuda.synchronize()\n",
    "            evaluator.process(inputs, outputs)\n",
    "\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    print(config)\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    results = evaluator.evaluate()\n",
    "    print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box mAP of Baseline Models\n",
    "\n",
    "| Baselines                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble using Weighted Boxes Fusion Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Detection Results and Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.93s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.87s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.32s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"./annotations/instances_val2017.json\"\n",
    "coco_gt = COCO(gt_path)\n",
    "\n",
    "dt_paths = [\n",
    "    \"./results/faster_rcnn_R_50_C4_1x/coco_instances_results.json\",\n",
    "    \"./results/faster_rcnn_R_50_C4_3x/coco_instances_results.json\",\n",
    "    \"./results/faster_rcnn_R_50_DC5_1x/coco_instances_results.json\",\n",
    "    # \"./results/faster_rcnn_R_50_DC5_3x/coco_instances_results.json\",\n",
    "    \"./results/faster_rcnn_R_50_FPN_1x/coco_instances_results.json\",\n",
    "    # \"./results/faster_rcnn_R_50_FPN_3x/coco_instances_results.json\",\n",
    "    # \"./results/faster_rcnn_R_101_DC5_3x/coco_instances_results.json\",\n",
    "    \"./results/retinanet_R_50_FPN_1x/coco_instances_results.json\",\n",
    "    \"./results/retinanet_R_50_FPN_3x/coco_instances_results.json\",\n",
    "    # \"./results/retinanet_R_101_FPN_3x/coco_instances_results.json\",\n",
    "    # \"./results/faster_rcnn_R_101_C4_3x/coco_instances_results.json\",\n",
    "]\n",
    "\n",
    "coco_dts = [coco_gt.loadRes(dt_path) for dt_path in dt_paths]\n",
    "img_ids = coco_gt.getImgIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.7, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:48<00:00, 102.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=43.71s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=8.61s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.462\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "iou_thr = 0.7\n",
    "skip_box_thr = 0.0001\n",
    "\n",
    "print(\"\\n================================================================\\n\")\n",
    "print(\"Ensemble using Weighted Boxes Fusion\")\n",
    "print(f\"iou thr: {iou_thr}, skip_box_thr: {skip_box_thr}\")\n",
    "print(\"\\n================================================================\\n\")\n",
    "\n",
    "ensemble = []\n",
    "cnt_id = 0\n",
    "iter = tqdm(img_ids, total=len(img_ids))\n",
    "for img_id in iter:\n",
    "    height = float(coco_gt.loadImgs(img_id)[0][\"height\"])\n",
    "    width = float(coco_gt.loadImgs(img_id)[0][\"width\"])\n",
    "\n",
    "    tmp_anns = []\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for coco_dt in coco_dts:\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        labels = []\n",
    "        for ann in coco_dt.imgToAnns[img_id]:\n",
    "            x1, y1 = ann[\"bbox\"][0], ann[\"bbox\"][1]\n",
    "            x2 = ann[\"bbox\"][0] + ann[\"bbox\"][2]\n",
    "            y2 = ann[\"bbox\"][1] + ann[\"bbox\"][3]\n",
    "            x1, x2 = x1/width, x2/width\n",
    "            y1, y2 = y1/height, y2/height\n",
    "\n",
    "            x1 = min(1.000, max(0.000, x1))\n",
    "            x2 = min(1.000, max(0.000, x2))\n",
    "            y1 = min(1.000, max(0.000, y1))\n",
    "            y2 = min(1.000, max(0.000, y2))\n",
    "                \n",
    "            boxes.append([x1,y1,x2,y2])\n",
    "            scores.append(ann[\"score\"])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        boxes_list.append(boxes)\n",
    "        scores_list.append(scores)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    boxes, scores, labels = ensemble_boxes.weighted_boxes_fusion(\n",
    "                                            boxes_list, \n",
    "                                            scores_list, \n",
    "                                            labels_list, \n",
    "                                            weights=None, \n",
    "                                            iou_thr=iou_thr, \n",
    "                                            skip_box_thr=skip_box_thr)\n",
    "\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        \n",
    "        x1 *= width\n",
    "        x2 *= width\n",
    "        y1 *= height\n",
    "        y2 *= height\n",
    "\n",
    "        ann = dict(\n",
    "            image_id=img_id,\n",
    "            category_id=label,\n",
    "            bbox=[x1, y1, x2-x1, y2-y1],\n",
    "            score=score,\n",
    "            id=cnt_id,\n",
    "        )\n",
    "\n",
    "        ensemble.append(ann)\n",
    "        \n",
    "        cnt_id += 1\n",
    "\n",
    "coco_ensemble = coco_gt.loadRes(ensemble)\n",
    "coco_eval = COCOeval(coco_gt, coco_ensemble, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|__Ensemble Model__   | __*0.403 (+0.029)*__|\n",
    "\n",
    "---\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|__Ensemble Model__   | __*0.411 (+0.032)*__|\n",
    "\n",
    "---\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|__Ensemble Model__   | __*0.418 (+0.034)*__|\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|retinanet_R_50_FPN_3x.yaml   | 0.387|\n",
    "|__Ensemble Model__   | __*0.425 (+0.038)*__|\n",
    "\n",
    "---\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_DC5_3x.yaml | 0.391|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|retinanet_R_50_FPN_3x.yaml   | 0.387|\n",
    "|__Ensemble Model__   | __*0.429 (+0.038)*__|\n",
    "\n",
    "---\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_DC5_3x.yaml | 0.391|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|faster_rcnn_R_50_FPN_3x.yaml | 0.402|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|retinanet_R_50_FPN_3x.yaml   | 0.387|\n",
    "|__Ensemble Model__   | __*0.434 (+0.032)*__|\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_DC5_3x.yaml | 0.391|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|faster_rcnn_R_50_FPN_3x.yaml | 0.402|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|retinanet_R_50_FPN_3x.yaml   | 0.387|\n",
    "|retinanet_R_101_FPN_3x.yaml  | 0.404|\n",
    "|__Ensemble Model__   | __*0.448 (+0.035)*__|\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "| Models                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_C4_3x.yaml  | 0.384|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|faster_rcnn_R_50_DC5_3x.yaml | 0.391|\n",
    "|faster_rcnn_R_50_FPN_1x.yaml | 0.379|\n",
    "|faster_rcnn_R_50_FPN_3x.yaml | 0.402|\n",
    "|faster_rcnn_R_101_DC5_3x.yaml| 0.406|\n",
    "|faster_rcnn_R_101_DC5_3x     | 0.411|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|\n",
    "|retinanet_R_50_FPN_3x.yaml   | 0.387|\n",
    "|retinanet_R_101_FPN_3x.yaml  | 0.404|\n",
    "|__Ensemble Model__   | __*0.448 (+0.037)*__|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble_detectron2",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a7cd6bd6adba24856cb99037131169106d508c2430b6d3766fea104d49690de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
