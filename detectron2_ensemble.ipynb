{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of Object Detection Models based on Detectron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Development Environment\n",
    "1. Environments\n",
    "    * OS: Ubuntu20.04\n",
    "    * CUDA: 11.3\n",
    "    * Pytorch==1.10\n",
    "    * Detectron2==0.6\n",
    "\n",
    "2. Installation\n",
    "    ```bash\n",
    "    sudo apt-get install -y python3-dev python3-venv\n",
    "    python3 -m venv env\n",
    "    source env/bin/activate\n",
    "    python -m pip install pip -U\n",
    "    python -m pip install -r requirements.txt\n",
    "    python -m ipykernel install --user --name env --display-name ensemble_detectron2\n",
    "    python -m pip install \"git+https://github.com/facebookresearch/detectron2@v0.6\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-25 21:56:30--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.173.113\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.173.113|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252907541 (241M) [application/zip]\n",
      "Saving to: ‘annotations_trainval2017.zip’\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.19M  8.34MB/s    in 56s     \n",
      "\n",
      "2022-08-25 21:57:27 (4.28 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
      "\n",
      "Archive:  annotations_trainval2017.zip\n",
      "  inflating: annotations/instances_train2017.json  \n",
      "  inflating: annotations/instances_val2017.json  \n",
      "  inflating: annotations/captions_train2017.json  \n",
      "  inflating: annotations/captions_val2017.json  \n",
      "  inflating: annotations/person_keypoints_train2017.json  \n",
      "  inflating: annotations/person_keypoints_val2017.json  \n"
     ]
    }
   ],
   "source": [
    "!wget -c http://images.cocodataset.org/zips/val2017.zip\n",
    "!unzip val2017.zip\n",
    "!rm val2017.zip\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip\n",
    "!rm annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "from detectron2.data.build import build_detection_test_loader\n",
    "from detectron2.evaluation.evaluator import inference_on_dataset\n",
    "from detectron2.evaluation.evaluator import inference_context\n",
    "from detectron2.structures import Instances, Boxes\n",
    "\n",
    "import ensemble_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Models, Data and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"dataset_val\", {}, \"./annotations/instances_val2017.json\", \"./val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_configs = [\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "]\n",
    "\n",
    "models = dict()\n",
    "for config in model_configs:\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{config}\"))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{config}\")\n",
    "    cfg.DATASETS.VAL = (\"dataset_val\",)\n",
    "\n",
    "    models[config] = DefaultPredictor(cfg).model\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.DATASETS.VAL = (\"dataset_val\",)\n",
    "val_loader = build_detection_test_loader(cfg, \"dataset_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  0%|          | 0/5000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 3.82 GiB total capacity; 2.14 GiB already allocated; 296.94 MiB free; 2.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/detectron2_ensemble.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/detectron2_ensemble.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39miter\u001b[39m \u001b[39m=\u001b[39m tqdm(val_loader, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(val_loader))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/detectron2_ensemble.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39miter\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/detectron2_ensemble.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/detectron2_ensemble.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39msynchronize()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/detectron2_ensemble.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     evaluator\u001b[39m.\u001b[39mprocess(inputs, outputs)\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:146\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m    batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m        \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(batched_inputs)\n\u001b[1;32m    148\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batched_inputs[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:209\u001b[0m, in \u001b[0;36mGeneralizedRCNN.inference\u001b[0;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mproposals\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batched_inputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    207\u001b[0m         proposals \u001b[39m=\u001b[39m [x[\u001b[39m\"\u001b[39m\u001b[39mproposals\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m batched_inputs]\n\u001b[0;32m--> 209\u001b[0m     results, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroi_heads(images, features, proposals, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     detected_instances \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m detected_instances]\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:477\u001b[0m, in \u001b[0;36mRes5ROIHeads.forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mdel\u001b[39;00m targets\n\u001b[1;32m    476\u001b[0m proposal_boxes \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mproposal_boxes \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m proposals]\n\u001b[0;32m--> 477\u001b[0m box_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shared_roi_transform(\n\u001b[1;32m    478\u001b[0m     [features[f] \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_features], proposal_boxes\n\u001b[1;32m    479\u001b[0m )\n\u001b[1;32m    480\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbox_predictor(box_features\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m[\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]))\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:457\u001b[0m, in \u001b[0;36mRes5ROIHeads._shared_roi_transform\u001b[0;34m(self, features, boxes)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_shared_roi_transform\u001b[39m(\u001b[39mself\u001b[39m, features: List[torch\u001b[39m.\u001b[39mTensor], boxes: List[Boxes]):\n\u001b[1;32m    456\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(features, boxes)\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mres5(x)\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201\u001b[0m, in \u001b[0;36mBottleneckBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n\u001b[1;32m    199\u001b[0m out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu_(out)\n\u001b[0;32m--> 201\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(out)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     shortcut \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/layers/wrappers.py:110\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mconv2d(\n\u001b[1;32m    107\u001b[0m     x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm(x)\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(x)\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/layers/batch_norm.py:57\u001b[0m, in \u001b[0;36mFrozenBatchNorm2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39m scale\u001b[39m.\u001b[39mto(out_dtype) \u001b[39m+\u001b[39m bias\u001b[39m.\u001b[39mto(out_dtype)\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[39m# When gradients are not needed, F.batch_norm is a single fused op\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39m# and provide more optimization opportunities.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m     58\u001b[0m         x,\n\u001b[1;32m     59\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean,\n\u001b[1;32m     60\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var,\n\u001b[1;32m     61\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m     63\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     64\u001b[0m         eps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m     65\u001b[0m     )\n",
      "File \u001b[0;32m~/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/torch/nn/functional.py:2282\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2280\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2282\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2283\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2284\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 3.82 GiB total capacity; 2.14 GiB already allocated; 296.94 MiB free; 2.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "for config, model in models.items():\n",
    "    evaluator = COCOEvaluator(\"dataset_val\", False, output_dir=f\"results/{config.split('.')[0]}\")\n",
    "    evaluator.reset()\n",
    "    with inference_context(model), torch.no_grad():\n",
    "        iter = tqdm(val_loader, total=len(val_loader))\n",
    "        for idx, inputs in enumerate(iter):\n",
    "            outputs = model(inputs)\n",
    "            torch.cuda.synchronize()\n",
    "            evaluator.process(inputs, outputs)\n",
    "\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    print(config)\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    results = evaluator.evaluate()\n",
    "    print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box mAP of Baseline Models\n",
    "\n",
    "| Baselines                   | Box AP @(IoU=0.50:0.95, area=all, maxDets=100) |\n",
    "|-----------------------------|------|\n",
    "|faster_rcnn_R_50_C4_1x.yaml  | 0.357|\n",
    "|faster_rcnn_R_50_DC5_1x.yaml | 0.373|\n",
    "|retinanet_R_50_FPN_1x.yaml   | 0.374|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble using Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "100%|██████████| 5000/5000 [20:47<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Non-Maximum Suppression\n",
      "iou_thr: 0.4\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.51s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.559\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.494\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:45<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Non-Maximum Suppression\n",
      "iou_thr: 0.5\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.06s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.517\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:48<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Non-Maximum Suppression\n",
      "iou_thr: 0.6000000000000001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.14s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:49<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Non-Maximum Suppression\n",
      "iou_thr: 0.7000000000000001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:50<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Non-Maximum Suppression\n",
      "iou_thr: 0.8\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.07s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:50<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Non-Maximum Suppression\n",
      "iou_thr: 0.9\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.05s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_ensemble_inputs(candidates):\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    classes_list = []\n",
    "    \n",
    "    for candiate in candidates:\n",
    "        assert len(candiate) == 1\n",
    "        assert len(candiate[0]) == 1\n",
    "\n",
    "        instances = candidates[0][0][\"instances\"]\n",
    "        image_size = instances.image_size\n",
    "        pred_boxes = instances.pred_boxes\n",
    "        scores = instances.scores\n",
    "        pred_classes = instances.pred_classes\n",
    "\n",
    "        # normalize\n",
    "        boxes = pred_boxes.tensor.tolist()\n",
    "        for box in boxes:\n",
    "            box[0] = box[0] / image_size[1]\n",
    "            box[1] = box[1] / image_size[0]\n",
    "            box[2] = box[2] / image_size[1]\n",
    "            box[3] = box[3] / image_size[0]\n",
    "\n",
    "        boxes_list.append(boxes)\n",
    "        scores_list.append(scores.tolist())\n",
    "        classes_list.append(pred_classes.tolist())\n",
    "\n",
    "    return boxes_list, scores_list, classes_list, image_size\n",
    "\n",
    "def build_instances(boxes, scores, labels, image_size):\n",
    "    for box in boxes:\n",
    "        box[0] = box[0] * image_size[1]\n",
    "        box[1] = box[1] * image_size[0]\n",
    "        box[2] = box[2] * image_size[1]\n",
    "        box[3] = box[3] * image_size[0]\n",
    "\n",
    "    ensemble_instances = Instances(image_size)\n",
    "    ensemble_instances.pred_boxes = Boxes(torch.as_tensor(boxes))\n",
    "    ensemble_instances.scores = torch.as_tensor(scores)\n",
    "    ensemble_instances.pred_classes = torch.as_tensor(labels)\n",
    "\n",
    "    return [dict(instances=ensemble_instances)]\n",
    "\n",
    "\n",
    "def predict_ensemble_nms(models, inputs, iou_thr):\n",
    "    candidates = []\n",
    "    for config, model in models.items():\n",
    "        with inference_context(model):\n",
    "            candidates.append(model(inputs))\n",
    "\n",
    "    boxes_list, scores_list, classes_list, image_size = build_ensemble_inputs(candidates)\n",
    "\n",
    "    weights = [1, 1, 1]\n",
    "\n",
    "    boxes, scores, labels = ensemble_boxes.nms(boxes_list, scores_list, classes_list, weights=weights, iou_thr=iou_thr)\n",
    "    \n",
    "    return build_instances(boxes, scores, labels, image_size)\n",
    "\n",
    "for i in range(4, 10):\n",
    "    iou_thr = i * 0.1\n",
    "    with torch.no_grad():\n",
    "        evaluator.reset()\n",
    "        iter = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "        for idx, inputs in enumerate(iter):\n",
    "            outputs = predict_ensemble_nms(models, inputs, iou_thr)\n",
    "            evaluator.process(inputs, outputs)\n",
    "\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    print(\"Ensemble using Non-Maximum Suppression\")\n",
    "    print(f\"iou_thr: {iou_thr}\")\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    results = evaluator.evaluate()\n",
    "    print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:44<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Soft Non-Maximum Suppression\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.94s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.565\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.578\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_ensemble_softnms(models, inputs):\n",
    "    candidates = []\n",
    "    for _, model in models.items():\n",
    "        with inference_context(model):\n",
    "            candidates.append(model(inputs))\n",
    "\n",
    "    boxes_list, scores_list, classes_list, image_size = build_ensemble_inputs(candidates)\n",
    "        \n",
    "    weights = [1, 1, 1]\n",
    "    iou_thr = 0.5\n",
    "    skip_box_thr = 0.0001\n",
    "    sigma = 0.1\n",
    "\n",
    "    boxes, scores, labels = ensemble_boxes.soft_nms(boxes_list, scores_list, classes_list, weights=weights, iou_thr=iou_thr, sigma=sigma, thresh=skip_box_thr)\n",
    "    \n",
    "    return build_instances(boxes, scores, labels, image_size)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    evaluator.reset()\n",
    "    iter = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "    for idx, inputs in enumerate(iter):\n",
    "        outputs = predict_ensemble_softnms(models, inputs)\n",
    "        evaluator.process(inputs, outputs)\n",
    "\n",
    "print(\"\\n================================================================\\n\")\n",
    "print(\"Ensemble using Soft Non-Maximum Suppression\")\n",
    "print(\"\\n================================================================\\n\")\n",
    "results = evaluator.evaluate()\n",
    "print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5000 [00:00<54:29,  1.53it/s]/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "100%|██████████| 5000/5000 [21:38<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Soft Non-Maximum Weighted\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.05s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_ensemble_non_maximum_weighted(models, inputs):\n",
    "    candidates = []\n",
    "    for _, model in models.items():\n",
    "        with inference_context(model):\n",
    "            candidates.append(model(inputs))\n",
    "\n",
    "    boxes_list, scores_list, classes_list, image_size = build_ensemble_inputs(candidates)\n",
    "        \n",
    "    weights = [1, 1, 1]\n",
    "    iou_thr = 0.5\n",
    "    skip_box_thr = 0.0001\n",
    "\n",
    "    boxes, scores, labels = ensemble_boxes.non_maximum_weighted(boxes_list, scores_list, classes_list, weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    \n",
    "    return build_instances(boxes, scores, labels, image_size)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    evaluator.reset()\n",
    "    iter = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "    for idx, inputs in enumerate(iter):\n",
    "        outputs = predict_ensemble_non_maximum_weighted(models, inputs)\n",
    "        evaluator.process(inputs, outputs)\n",
    "\n",
    "print(\"\\n================================================================\\n\")\n",
    "print(\"Ensemble using Soft Non-Maximum Weighted\")\n",
    "print(\"\\n================================================================\\n\")\n",
    "results = evaluator.evaluate()\n",
    "print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/kyungpyo/git/Ensemble-Object-Detection-using-Detectron2/env/lib/python3.8/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "100%|██████████| 5000/5000 [21:23<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.4, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=0.88s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:21<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.5, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.14s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.556\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.390\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:22<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.6000000000000001, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.12s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:18<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.7000000000000001, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.18s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:22<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.8, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.13s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.566\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:23<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================\n",
      "\n",
      "Ensemble using Weighted Boxes Fusion\n",
      "iou thr: 0.9, skip_box_thr: 0.0001\n",
      "\n",
      "================================================================\n",
      "\n",
      "Loading and preparing results...\n",
      "DONE (t=1.12s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n",
      "\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_ensemble_weighted_boxes_fusion(models, inputs, param):\n",
    "    candidates = []\n",
    "    for _, model in models.items():\n",
    "        with inference_context(model):\n",
    "            candidates.append(model(inputs))\n",
    "\n",
    "    boxes_list, scores_list, classes_list, image_size = build_ensemble_inputs(candidates)\n",
    "\n",
    "\n",
    "    iou_thr, skip_box_thr = param\n",
    "\n",
    "    boxes, scores, labels = ensemble_boxes.weighted_boxes_fusion(boxes_list, scores_list, classes_list, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    \n",
    "    return build_instances(boxes, scores, labels, image_size)\n",
    "\n",
    "\n",
    "for i in range(4,10):\n",
    "    iou_thr = i * 0.1\n",
    "    skip_box_thr = 0.0001\n",
    "    with torch.no_grad():\n",
    "        evaluator.reset()\n",
    "        iter = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "        for idx, inputs in enumerate(iter):\n",
    "            outputs = predict_ensemble_weighted_boxes_fusion(models, inputs, (iou_thr, skip_box_thr))\n",
    "            evaluator.process(inputs, outputs)\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    print(\"Ensemble using Weighted Boxes Fusion\")\n",
    "    print(f\"iou thr: {iou_thr}, skip_box_thr: {skip_box_thr}\")\n",
    "    print(\"\\n================================================================\\n\")\n",
    "    results = evaluator.evaluate()\n",
    "    print(\"\\n================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model_config = [\n",
    "        \"retinanet_R_50_FPN_1x.yaml\",\n",
    "        \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "        \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    ]\n",
    "\n",
    "    for config in model_config:\n",
    "        print(\"\\n================================================================\\n\")\n",
    "        print(config )\n",
    "        print(\"\\n================================================================\\n\")\n",
    "\n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{config}\"))\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{config}\")\n",
    "        cfg.DATASETS.VAL = (\"dataset_val\",)\n",
    "\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "\n",
    "        evaluator = COCOEvaluator(\"dataset_val\", False, output_dir=\"output\")\n",
    "        val_loader = build_detection_test_loader(cfg, \"dataset_val\")\n",
    "        inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "\n",
    "        print(\"\\n================================================================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a7cd6bd6adba24856cb99037131169106d508c2430b6d3766fea104d49690de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
